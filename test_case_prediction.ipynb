{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3XoGBQn90RMr",
        "outputId": "29400cae-92f9-40de-8640-c2a5bb69d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.50.2-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.50.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Enter_API_key\"\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Load the Excel file containing test cases\n",
        "df = pd.read_excel('/content/drive/MyDrive/sample_test_cases.xlsx')\n",
        "\n",
        "# Preprocess the data (convert Yes/No to 1/0 for machine learning)\n",
        "df['Test Case Passed (Yes/No)'] = df['Test Case Passed (Yes/No)'].map({'Yes': 1, 'No': 0})\n",
        "df['Failure Reason'] = df['Failure Reason'].fillna('No Failure')\n",
        "\n",
        "# Feature engineering (e.g., failure reason length)\n",
        "df['Failure Length'] = df['Failure Reason'].apply(len)\n",
        "\n",
        "# Group by test case ID (assuming there's a 'Test Case ID' column)\n",
        "grouped_df = df.groupby('Test Case ID')\n",
        "\n",
        "# Initialize a new DataFrame to hold the final predictions and AI suggestions\n",
        "final_predictions = []\n",
        "\n",
        "# Function to predict whether a test case will pass or fail overall\n",
        "def predict_test_case_outcome(test_case_data):\n",
        "    # Prepare data for machine learning based on the aggregated data of this test case\n",
        "    X = test_case_data[['Failure Length']]\n",
        "    y = test_case_data['Test Case Passed (Yes/No)']\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train a RandomForest model (or any other model)\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make a prediction based on the entire test case's data\n",
        "    return model.predict(X_test).mean() >= 0.5  # Predict 1 (pass) if the average prediction is >= 0.5\n",
        "\n",
        "# Function to get fix suggestions using OpenAI\n",
        "def get_fix_suggestions(failure_reason):\n",
        "    if failure_reason == 'No Failure':  # No suggestion for successful cases\n",
        "        return 'N/A'\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"The test case failed due to the following reason: {failure_reason}. How can this issue be fixed?\"}\n",
        "            ]\n",
        "        )\n",
        "        # Return the suggested fix\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Process each test case group\n",
        "for test_case_id, test_case_data in grouped_df:\n",
        "    # Predict the overall outcome for this test case\n",
        "    will_pass = predict_test_case_outcome(test_case_data)\n",
        "\n",
        "    # If the test case will fail, generate AI suggestions\n",
        "    failure_reasons = test_case_data['Failure Reason'].unique()  # Get unique failure reasons\n",
        "    ai_suggestions = []\n",
        "\n",
        "    if not will_pass:  # Only generate suggestions for failing cases\n",
        "        for reason in failure_reasons:\n",
        "            if reason != 'No Failure':\n",
        "                suggestion = get_fix_suggestions(reason)\n",
        "                ai_suggestions.append(f\"{reason}: {suggestion}\")\n",
        "\n",
        "    # Summarize the results into a new row for the final predictions DataFrame\n",
        "    final_row = {\n",
        "        'Test Case ID': test_case_id,\n",
        "        'Overall Prediction (Pass/Fail)': 'Yes' if will_pass else 'No',\n",
        "        'AI Suggestions': \"; \".join(ai_suggestions) if ai_suggestions else 'N/A'\n",
        "    }\n",
        "\n",
        "    final_predictions.append(final_row)\n",
        "\n",
        "# Convert final predictions list to DataFrame\n",
        "final_predictions_df = pd.DataFrame(final_predictions)\n",
        "\n",
        "# Save the final predictions and AI suggestions to a new Excel file\n",
        "output_file = 'test_case_overall_predictions_with_ai_suggestions.xlsx'\n",
        "final_predictions_df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Overall predictions with AI suggestions saved to {output_file}\")\n",
        "\n",
        "# (Optional) If you're using Google Colab, download the output file\n",
        "from google.colab import files\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "id": "cMCrkFSx0Rtc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f05b4edc-7481-4f29-95ba-89037c2066c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall predictions with AI suggestions saved to test_case_overall_predictions_with_ai_suggestions.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4f86ae6-befb-4577-95b7-fd2d610e2a7d\", \"test_case_overall_predictions_with_ai_suggestions.xlsx\", 5318)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}